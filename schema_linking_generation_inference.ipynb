{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZK83JZaKSxu2",
    "outputId": "174c225b-5dbc-4412-8786-6d1832092ca4"
   },
   "outputs": [],
   "source": [
    "!pip install -U accelerate bitsandbytes peft transformers datasets trl git-lfs wandb flash-attn sql-metadata scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "690Zw7_2SkCU"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, BitsAndBytesConfig\n",
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from torch import cuda\n",
    "from sql_metadata import Parser\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "f0d5986597124099bf09d298575c5126",
      "6e2db7ee351248f4b08587a275bfde8a",
      "30c71ab2e03d40d7968624b3dc15656c",
      "16576d8e9bca4a978cf1807800d2993f",
      "4fde92ad16cc4bd18d9c48dc91d28696",
      "08d81d35451441abb5a8069816d96bf4",
      "eed7debb70434c16aeda3d744d131d30",
      "a49f174c025644d7a99e414244390a0d",
      "f30459f7d7254a7abc3cabe448a60681",
      "f87cf27bd7aa4c5fbcb796155236a983",
      "a0010a2bcdc94d609fe271442e1db441"
     ]
    },
    "id": "11wfu6AdTK1C",
    "outputId": "56652c73-e2f9-492b-ba43-826ba5cde889"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
    "# model_name = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "model_base_name = os.path.basename(model_name)\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_4bit_compute_dtype = torch.float16,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    attn_implementation=\"flash_attention_2\", # use with amper architecture\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    #quantization_config=bnb_config, # use when low on memory\n",
    "    device_map = \"auto\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "kUqzZ2bFVdd9",
    "outputId": "5a572914-766e-4b93-cb67-a31efc786bb8"
   },
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(model, f\"final_checkpoint/{model_base_name}\", torch_dtype = torch.bfloat16)\n",
    "model = model.merge_and_unload()\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.encode(' ;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'deepseek' in model_base_name:\n",
    "  special_end_token = ' ;'\n",
    "elif 'Mistral' in model_base_name:\n",
    "  special_end_token = ';'\n",
    "else:\n",
    "  special_end_token = ';'\n",
    "special_end_token_id = tokenizer.encode(special_end_token, add_special_tokens=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria\n",
    "class EosListStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, eos_sequence):\n",
    "        self.eos_sequence = eos_sequence\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
    "        last_ids = input_ids[:,-len(self.eos_sequence):].tolist()\n",
    "        return self.eos_sequence in last_ids\n",
    "    \n",
    "def append_string_to_file(text, file_path):\n",
    "  with open(file_path, 'a') as file:\n",
    "      file.write(text + '\\n')\n",
    "\n",
    "def remove_spaces(text):\n",
    "  return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def call_llm(inputs, special_end_token_id):\n",
    "  output_tokens = model.generate(inputs, max_new_tokens=250, do_sample=False, pad_token_id=tokenizer.eos_token_id, eos_token_id=tokenizer.eos_token_id, stopping_criteria = [EosListStoppingCriteria(eos_sequence=[special_end_token_id])])\n",
    "  return tokenizer.decode(output_tokens[0][len(inputs[0]):], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgz-2h6SVj1Z",
    "outputId": "ff9a916b-c865-4e74-b4ca-9dcb8de57730"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"validation_dataset.csv\")\n",
    "results = []\n",
    "for index, row in tqdm(df.iterrows(), total=len(df)):\n",
    "  question = row['question']\n",
    "  query = row['query']\n",
    "  database_schema = row['database_schema']\n",
    "  db_id = row['db_id']\n",
    "  user_message = f\"\"\"Given the following SQL tables, your job is to determine the columns and tables that the question is referring to.\n",
    "{database_schema}\n",
    "###\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "  messages = [\n",
    "      {\"role\": \"user\", \"content\": user_message.strip()}\n",
    "  ]\n",
    "  inputs = tokenizer.apply_chat_template(messages, return_tensors=\"pt\",add_generation_prompt=True,tokenize = True).to(model.device)\n",
    "  response = call_llm(inputs, special_end_token_id)\n",
    "  raw_response = response\n",
    "  if \";\" in response:\n",
    "    response = response.split(\";\")[0]\n",
    "    if \"Tables:\" in response:\n",
    "      response = response.split(\"Tables:\")[1]\n",
    "  response = re.sub(r'\\s+', ' ', response).strip()\n",
    "  try:\n",
    "    ref_rables = \", \".join(Parser(query).tables)\n",
    "  except Exception:\n",
    "    continue\n",
    "  print(\"\\n\")\n",
    "  print(response)\n",
    "  print(ref_rables)\n",
    "  print(\"============================\")\n",
    "  results.append([raw_response, response, ref_rables, query,row['question'],row['db_id']])\n",
    "  new_df = pd.DataFrame(results, columns = ['raw_response', 'predicted_tables','reference_tables','query','question','db_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = len(new_df)\n",
    "total_accuracy = 0\n",
    "filtered_accuracy = 0\n",
    "total_precision = 0\n",
    "total_recall = 0\n",
    "\n",
    "for index, row in new_df.iterrows():\n",
    "    \n",
    "    if not row['predicted_tables'] or pd.isna(row['predicted_tables']):\n",
    "        continue\n",
    "    predicted_tables = row['predicted_tables'].split(\", \")\n",
    "    reference_tables = row['reference_tables'].split(\", \")\n",
    "    \n",
    "    # Convert to lowercase and strip whitespace for comparison\n",
    "    predicted_tables = [x.lower().replace(\"--\",\"\").replace(\"**\",\"\").strip() for x in predicted_tables]\n",
    "    reference_tables = [x.lower().strip() for x in reference_tables]\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    if set(predicted_tables) == set(reference_tables):\n",
    "        total_accuracy += 1\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    true_positives = len(set(predicted_tables) & set(reference_tables))\n",
    "    false_positives = len(set(predicted_tables) - set(reference_tables))\n",
    "    false_negatives = len(set(reference_tables) - set(predicted_tables))\n",
    "\n",
    "    if true_positives == len(reference_tables):\n",
    "        filtered_accuracy += 1\n",
    "    \n",
    "    if len(predicted_tables) > 0:\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "    \n",
    "    total_precision += precision\n",
    "    total_recall += recall\n",
    "\n",
    "# Calculate average precision and recall\n",
    "avg_precision = total_precision / total_samples\n",
    "avg_recall = total_recall / total_samples\n",
    "\n",
    "# Calculate total accuracy\n",
    "accuracy = total_accuracy / total_samples\n",
    "filtered_accuracy = filtered_accuracy / total_samples\n",
    "\n",
    "print(\"Total Accuracy:\", accuracy)\n",
    "print(\"Filtered Accuracy:\", filtered_accuracy)\n",
    "print(\"Average Precision:\", avg_precision)\n",
    "print(\"Average Recall:\", avg_recall)\n",
    "\n",
    "new_df.to_csv(\"generated_schema_links.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "08d81d35451441abb5a8069816d96bf4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16576d8e9bca4a978cf1807800d2993f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f87cf27bd7aa4c5fbcb796155236a983",
      "placeholder": "​",
      "style": "IPY_MODEL_a0010a2bcdc94d609fe271442e1db441",
      "value": " 2/2 [01:14&lt;00:00, 34.39s/it]"
     }
    },
    "30c71ab2e03d40d7968624b3dc15656c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a49f174c025644d7a99e414244390a0d",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f30459f7d7254a7abc3cabe448a60681",
      "value": 2
     }
    },
    "4fde92ad16cc4bd18d9c48dc91d28696": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e2db7ee351248f4b08587a275bfde8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08d81d35451441abb5a8069816d96bf4",
      "placeholder": "​",
      "style": "IPY_MODEL_eed7debb70434c16aeda3d744d131d30",
      "value": "Loading checkpoint shards: 100%"
     }
    },
    "a0010a2bcdc94d609fe271442e1db441": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a49f174c025644d7a99e414244390a0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eed7debb70434c16aeda3d744d131d30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f0d5986597124099bf09d298575c5126": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e2db7ee351248f4b08587a275bfde8a",
       "IPY_MODEL_30c71ab2e03d40d7968624b3dc15656c",
       "IPY_MODEL_16576d8e9bca4a978cf1807800d2993f"
      ],
      "layout": "IPY_MODEL_4fde92ad16cc4bd18d9c48dc91d28696"
     }
    },
    "f30459f7d7254a7abc3cabe448a60681": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f87cf27bd7aa4c5fbcb796155236a983": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
